{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08d53e4",
   "metadata": {},
   "source": [
    "# 04 \u2014 Train LightGBM veto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install torch numpy pandas pyarrow scikit-learn lightgbm tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, pathlib\n",
    "\n",
    "REPO_URL = os.getenv('REPO_URL', 'https://github.com/RishiKarthikeyan07/ai-trader-saas')\n",
    "REPO_DIR = os.getenv('REPO_DIR', 'AI_TRADER')\n",
    "\n",
    "if not pathlib.Path('backend').exists():\n",
    "    if not pathlib.Path(REPO_DIR).exists():\n",
    "        !git clone $REPO_URL $REPO_DIR\n",
    "    %cd $REPO_DIR\n",
    "sys.path.append(str(pathlib.Path('backend').resolve()))\n",
    "\n",
    "DATASET_PATH = pathlib.Path('training_data/v1/dataset.parquet')\n",
    "\n",
    "train_df = None\n",
    "val_df = None\n",
    "\n",
    "assert DATASET_PATH.exists(), f\"Dataset not found at {DATASET_PATH}\"\n",
    "print(f'Using dataset: {DATASET_PATH}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "\n",
    "from app.ml.preprocess.normalize import build_veto_vec\n",
    "from app.ml.stockformer.model import StockFormer\n",
    "from app.ml.tft.model import TFT\n",
    "\n",
    "DATASET_PATH = pathlib.Path('training_data/v1/dataset.parquet')\n",
    "df = pd.read_parquet(DATASET_PATH).sort_values('asof').reset_index(drop=True)\n",
    "split = int(0.8 * len(df))\n",
    "train_df, val_df = df.iloc[:split], df.iloc[split:]\n",
    "print(f'Train: {len(train_df)}, Val: {len(val_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e15f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained SF/TFT\n",
    "sf = StockFormer(lookback=120, price_dim=5, kronos_dim=512, context_dim=29, d_model=128, n_heads=4, n_layers=4, ffn_dim=256, dropout=0.1)\n",
    "sf.load_state_dict(torch.load('artifacts/v1/stockformer/weights.pt', map_location='cpu'))\n",
    "sf.eval()\n",
    "\n",
    "tft = TFT(lookback=120, price_dim=5, kronos_dim=512, context_dim=29, emb_dim=64, dropout=0.1)\n",
    "tft.load_state_dict(torch.load('artifacts/v1/tft/weights.pt', map_location='cpu'))\n",
    "tft.eval()\n",
    "\n",
    "def split_ctx(ctx: np.ndarray):\n",
    "    a = np.asarray(ctx, dtype=np.float32).reshape(-1)\n",
    "    tf_align = a[:5]\n",
    "    smc_vec = a[5:17]\n",
    "    ta_vec = a[17:]\n",
    "    return tf_align, smc_vec, ta_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb063f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vectors(frame: pd.DataFrame, max_rows: int | None = None):\n",
    "    X, y = [], []\n",
    "    iterator = frame if max_rows is None else frame.sample(min(max_rows, len(frame)), random_state=42)\n",
    "\n",
    "    def _arr_price(x, idx=None):\n",
    "        try:\n",
    "            a = np.array(x, dtype=np.float32)\n",
    "        except Exception:\n",
    "            a = np.array(list(x), dtype=object)\n",
    "            a = np.stack([np.array(row, dtype=np.float32).reshape(-1) for row in a], axis=0)\n",
    "        if a.size != 120 * 5:\n",
    "            raise ValueError(f\"Bad ohlcv_norm size for idx {idx}: shape {a.shape}\")\n",
    "        return a.reshape(1, 120, 5)\n",
    "\n",
    "    def _arr_flat(x, name, idx=None):\n",
    "        try:\n",
    "            a = np.array(x, dtype=np.float32).reshape(1, -1)\n",
    "        except Exception as exc:\n",
    "            raise ValueError(f\"Bad array for {name} at idx {idx}: {x}\") from exc\n",
    "        return a\n",
    "\n",
    "    for i, (_, r) in enumerate(iterator.iterrows()):\n",
    "        x_price = torch.tensor(_arr_price(r['ohlcv_norm'], idx=i))\n",
    "        x_kron = torch.tensor(_arr_flat(r['kronos_emb'], 'kronos_emb', idx=i))\n",
    "        x_ctx = torch.tensor(_arr_flat(r['context'], 'context', idx=i))\n",
    "        with torch.no_grad():\n",
    "            sf_out = sf(x_price, x_kron, x_ctx)\n",
    "            tft_out = tft(x_price, x_kron, x_ctx)\n",
    "        tf_align, smc_vec, ta_vec = split_ctx(r['context'])\n",
    "        veto_vec = build_veto_vec(\n",
    "            sf_out={'prob': sf_out['up_prob'].numpy(), 'ret': sf_out['ret'].numpy()},\n",
    "            tft_out={k: v.numpy() for k, v in tft_out.items()},\n",
    "            smc_vec=smc_vec,\n",
    "            tf_align=tf_align,\n",
    "            ta_vec=ta_vec,\n",
    "            raw_features={}\n",
    "        )\n",
    "        X.append(veto_vec.squeeze(0))\n",
    "        y.append(int(np.array(r['y_up'])[1]))\n",
    "    return np.stack(X, axis=0), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = infer_vectors(train_df, max_rows=50000)\n",
    "X_val, y_val = infer_vectors(val_df, max_rows=10000)\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective='binary',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='logloss',\n",
    "    verbose=50,\n",
    ")\n",
    "\n",
    "booster = lgbm.booster_\n",
    "booster.save_model('artifacts/v1/veto/lightgbm.txt')\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "Path('artifacts/v1/veto').mkdir(parents=True, exist_ok=True)\n",
    "with open('artifacts/v1/veto/config.json','w') as f:\n",
    "    json.dump({'name':'lightgbm_veto_v1','threshold_block':0.65,'threshold_boost':0.35}, f, indent=2)\n",
    "print('Saved LightGBM veto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artifact summary for LightGBM veto\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "\n",
    "w_path = Path('artifacts/v1/veto/lightgbm.txt')\n",
    "c_path = Path('artifacts/v1/veto/config.json')\n",
    "print('Artifacts directory exists:', w_path.parent.exists())\n",
    "print('LightGBM model exists:', w_path.exists(), w_path)\n",
    "print('Config exists:', c_path.exists(), c_path)\n",
    "if c_path.exists():\n",
    "    print(c_path.read_text())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}